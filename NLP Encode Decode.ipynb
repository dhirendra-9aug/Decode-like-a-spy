{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import string\n",
    "import random\n",
    "import re\n",
    "import requests\n",
    "import os\n",
    "import textwrap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### key and value for our encryption and decryption\n",
    "letters1 = list(string.ascii_lowercase)\n",
    "letters2 = list(string.ascii_lowercase)\n",
    "print(letters2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## empty list\n",
    "true_mapping={}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## get our first mapping\n",
    "random.shuffle(letters2)\n",
    "print(letters2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "true_mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## generating a true mapping which only the sender and decrypter know\n",
    "for k, v in zip(letters1 , letters2) :\n",
    " true_mapping[k]=v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# modelling\n",
    "# markov"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## blank matrix for Bigrams probabilities\n",
    "M= np.ones((26,26))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## blank matrix for unigrams probabbilities\n",
    "pi = np.ones(26)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a function to update the Markov matrix\n",
    "def update_transition(ch1, ch2):\n",
    " i = ord(ch1) - 97\n",
    " j = ord(ch2) - 97\n",
    " M[i,j] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a function to update the initial state distribution\n",
    "def update_pi(ch):\n",
    "  i = ord(ch) - 97\n",
    "  pi[i] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the log-probability of a word / token\n",
    "def get_word_prob(word):\n",
    "  # print(\"word:\", word)\n",
    "  i = ord(word[0]) - 97\n",
    "  logp = np.log(pi[i])\n",
    "\n",
    "  for ch in word[1:]:\n",
    "    j = ord(ch) - 97\n",
    "    logp += np.log(M[i, j]) # update prob\n",
    "    i = j # update j\n",
    "\n",
    "  return logp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_word_prob(word):\n",
    "  # print(\"word:\", word)\n",
    "  i = ord(word[0]) - 97\n",
    "  logp = np.log(pi[i])\n",
    "\n",
    "  for ch in word[1:]:\n",
    "    j = ord(ch) - 97\n",
    "    logp += np.log(M[i, j]) # update prob\n",
    "    i = j # update j\n",
    "\n",
    "  return logp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the probability of a sequence of words\n",
    "def get_sequence_prob(words):\n",
    "  # if input is a string, split into an array of tokens\n",
    "  if type(words) == str:\n",
    "    words = words.split()\n",
    "\n",
    "  logp = 0\n",
    "  for word in words:\n",
    "    logp += get_word_prob(word)\n",
    "  return logp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for replacing non-alpha characters\n",
    "regex = re.compile('[^a-zA-Z]')\n",
    "\n",
    "# load in words\n",
    "for line in open('C:\\\\Users\\\\62408\\\\Desktop\\\\python\\\\NLP\\\\machine_learning_examples-master\\\\nlp_class3\\\\file.txt',\"r\",encoding=\"utf-8\"):\n",
    "  line = line.rstrip()\n",
    "\n",
    "  # there are blank lines in the file\n",
    "  if line:\n",
    "    line = regex.sub(' ', line) # replace all non-alpha characters with space\n",
    "\n",
    "    # split the tokens in the line and lowercase\n",
    "    tokens = line.lower().split()\n",
    "\n",
    "    for token in tokens:\n",
    "      # update the model\n",
    "\n",
    "      # first letter\n",
    "      ch0 = token[0]\n",
    "      update_pi(ch0)\n",
    "\n",
    "      # other letters\n",
    "      for ch1 in token[1:]:\n",
    "        update_transition(ch0, ch1)\n",
    "        ch0 = ch1\n",
    "\n",
    "# normalize the probabilities\n",
    "pi /= pi.sum()\n",
    "M /= M.sum(axis=1, keepdims=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "original_message = '''I then lounged down the street and found,\n",
    "as I expected, that there was a mews in a lane which runs down\n",
    "by one wall of the garden. I lent the ostlers a hand in rubbing\n",
    "down their horses, and received in exchange twopence, a glass of\n",
    "half-and-half, two fills of shag tobacco, and as much information\n",
    "as I could desire about Miss Adler, to say nothing of half a dozen\n",
    "other people in the neighbourhood in whom I was not in the least\n",
    "interested, but whose biographies I was compelled to listen to.\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a function to encode a message\n",
    "def encode_message(msg):\n",
    "  # downcase\n",
    "  msg = msg.lower()\n",
    "\n",
    "  # replace non-alpha characters\n",
    "  msg = regex.sub(' ', msg)\n",
    "\n",
    "  # make the encoded message\n",
    "  coded_msg = []\n",
    "  for ch in msg:\n",
    "    coded_ch = ch # could just be a space\n",
    "    if ch in true_mapping:\n",
    "      coded_ch = true_mapping[ch]\n",
    "    coded_msg.append(coded_ch)\n",
    "\n",
    "  return ''.join(coded_msg)\n",
    "\n",
    "\n",
    "encoded_message = encode_message(original_message)\n",
    "\n",
    "\n",
    "# a function to decode a message\n",
    "def decode_message(msg, word_map):\n",
    "  decoded_msg = []\n",
    "  for ch in msg:\n",
    "    decoded_ch = ch # could just be a space\n",
    "    if ch in word_map:\n",
    "      decoded_ch = word_map[ch]\n",
    "    decoded_msg.append(decoded_ch)\n",
    "\n",
    "  return ''.join(decoded_msg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### run an evolutionary algorithm to decode the message\n",
    "\n",
    "# this is our initialization point\n",
    "dna_pool = []\n",
    "for _ in range(20):\n",
    "  dna = list(string.ascii_lowercase)\n",
    "  random.shuffle(dna)\n",
    "  dna_pool.append(dna)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evolve_offspring(dna_pool, n_children):\n",
    "  # make n_children per offspring\n",
    "  offspring = []\n",
    "\n",
    "  for dna in dna_pool:\n",
    "    for _ in range(n_children):\n",
    "      copy = dna.copy()\n",
    "      j = np.random.randint(len(copy))\n",
    "      k = np.random.randint(len(copy))\n",
    "\n",
    "      # switch\n",
    "      tmp = copy[j]\n",
    "      copy[j] = copy[k]\n",
    "      copy[k] = tmp\n",
    "      offspring.append(copy)\n",
    "\n",
    "  return offspring + dna_pool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "num_iters = 1000\n",
    "scores = np.zeros(num_iters)\n",
    "best_dna = None\n",
    "best_map = None\n",
    "best_score = float('-inf')\n",
    "for i in range(num_iters):\n",
    "  if i > 0:\n",
    "    # get offspring from the current dna pool\n",
    "    dna_pool = evolve_offspring(dna_pool, 3)\n",
    "\n",
    "  # calculate score for each dna\n",
    "  dna2score = {}\n",
    "  for dna in dna_pool:\n",
    "    # populate map\n",
    "    current_map = {}\n",
    "    for k, v in zip(letters1, dna):\n",
    "      current_map[k] = v\n",
    "\n",
    "    decoded_message = decode_message(encoded_message, current_map)\n",
    "    score = get_sequence_prob(decoded_message)\n",
    "\n",
    "    # store it\n",
    "    # needs to be a string to be a dict key\n",
    "    dna2score[''.join(dna)] = score\n",
    "\n",
    "    # record the best so far\n",
    "    if score > best_score:\n",
    "      best_dna = dna\n",
    "      best_map = current_map\n",
    "      best_score = score\n",
    "\n",
    "  # average score for this generation\n",
    "  scores[i] = np.mean(list(dna2score.values()))\n",
    "\n",
    "  # keep the best 5 dna\n",
    "  # also turn them back into list of single chars\n",
    "  sorted_dna = sorted(dna2score.items(), key=lambda x: x[1], reverse=True)\n",
    "  dna_pool = [list(k) for k, v in sorted_dna[:5]]\n",
    "\n",
    "  if i % 200 == 0:\n",
    "    print(\"iter:\", i, \"score:\", scores[i], \"best so far:\", best_score)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# use best score\n",
    "decoded_message = decode_message(encoded_message, best_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print the final decoded message\n",
    "print(\"Decoded message:\\n\", textwrap.fill(decoded_message))\n",
    "\n",
    "print(\"\\nTrue message:\\n\", original_message)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
